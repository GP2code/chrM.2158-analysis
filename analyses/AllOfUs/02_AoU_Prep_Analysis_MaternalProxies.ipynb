{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association of chrM2158T>C variant with PD risk in AllOfUs\n",
    "* **Project:** Mitochondrial 2158T>C variant in PD\n",
    "* **Version:** Python/3.9\n",
    "* **Status:** COMPLETE\n",
    "* **Last Updated:** 07-APRIL-2024\n",
    "\n",
    "### Notebook Overview\n",
    "Querying AllOfUs to extract maternal proxy cases CRAM files, merge them, use Mutect2 and PLINK2 for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a568c8f991ee43d1b931621dbc79b2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0/1110 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"pd_maternal_proxy\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_46445045_person_sql = \"\"\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.gender_concept_id,\n",
    "        p_gender_concept.concept_name as gender,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        person.race_concept_id,\n",
    "        p_race_concept.concept_name as race,\n",
    "        person.ethnicity_concept_id,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        person.sex_at_birth_concept_id,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".person` person \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_gender_concept \n",
    "            ON person.gender_concept_id = p_gender_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "    WHERE\n",
    "        person.PERSON_ID IN (\n",
    "            SELECT\n",
    "                distinct person_id  \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "            WHERE\n",
    "                cb_search_person.person_id IN (\n",
    "                    SELECT\n",
    "                        criteria.person_id \n",
    "                    FROM\n",
    "                        (SELECT\n",
    "                            DISTINCT person_id,\n",
    "                            entry_date,\n",
    "                            concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                        WHERE\n",
    "                            (\n",
    "                                concept_id IN (836812) \n",
    "                                AND is_standard = 0  \n",
    "                                AND  value_source_concept_id IN (43529690)\n",
    "                            )) criteria ) \n",
    "                        AND cb_search_person.person_id IN (SELECT\n",
    "                            person_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                        WHERE\n",
    "                            has_whole_genome_variant = 1 ) \n",
    "                        AND cb_search_person.person_id NOT IN (SELECT\n",
    "                            criteria.person_id \n",
    "                        FROM\n",
    "                            (SELECT\n",
    "                                DISTINCT person_id,\n",
    "                                entry_date,\n",
    "                                concept_id \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                            WHERE\n",
    "                                (\n",
    "                                    concept_id IN (\n",
    "                                        SELECT\n",
    "                                            DISTINCT c.concept_id \n",
    "                                        FROM\n",
    "                                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                                        JOIN\n",
    "                                            (\n",
    "                                                select\n",
    "                                                    cast(cr.id as string) as id \n",
    "                                                FROM\n",
    "                                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                                                WHERE\n",
    "                                                    concept_id IN (381270) \n",
    "                                                    AND full_text LIKE '%_rank1]%'\n",
    "                                            ) a \n",
    "                                                ON (\n",
    "                                                    c.path LIKE CONCAT('%.',\n",
    "                                                a.id,\n",
    "                                                '.%') \n",
    "                                                OR c.path LIKE CONCAT('%.',\n",
    "                                                a.id) \n",
    "                                                OR c.path LIKE CONCAT(a.id,\n",
    "                                                '.%') \n",
    "                                                OR c.path = a.id) \n",
    "                                            WHERE\n",
    "                                                is_standard = 1 \n",
    "                                                AND is_selectable = 1\n",
    "                                            ) \n",
    "                                            AND is_standard = 1 \n",
    "                                    )\n",
    "                                ) criteria \n",
    "                            ) )\"\"\"\n",
    "\n",
    "dataset_46445045_person_df = pandas.read_gbq(\n",
    "    dataset_46445045_person_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "\n",
    "# To write the DataFrame to a CSV file:\n",
    "dataset_46445045_person_df.to_csv(\"mar2_matproxy_person_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2078f5fc4cb54fafb9605b417bf1472a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0/24488 [00:00<?, ?rows/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"pd_maternal_proxy\" for domain \"survey\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_46445045_survey_sql = \"\"\"\n",
    "    SELECT\n",
    "        answer.person_id,\n",
    "        answer.survey_datetime,\n",
    "        answer.survey,\n",
    "        answer.question_concept_id,\n",
    "        answer.question,\n",
    "        answer.answer_concept_id,\n",
    "        answer.answer,\n",
    "        answer.survey_version_concept_id,\n",
    "        answer.survey_version_name  \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".ds_survey` answer   \n",
    "    WHERE\n",
    "        (\n",
    "            question_concept_id IN (\n",
    "                836812\n",
    "            ) \n",
    "            OR question_concept_id IN (\n",
    "                SELECT\n",
    "                    DISTINCT concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                JOIN\n",
    "                    (\n",
    "                        select\n",
    "                            cast(cr.id as string) as id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                        WHERE\n",
    "                            concept_id IN (\n",
    "                                1586134\n",
    "                            ) \n",
    "                            AND domain_id = 'SURVEY'\n",
    "                    ) a \n",
    "                        ON (\n",
    "                            c.path like CONCAT('%',\n",
    "                        a.id,\n",
    "                        '.%')) \n",
    "                    WHERE\n",
    "                        domain_id = 'SURVEY' \n",
    "                        AND type = 'PPI' \n",
    "                        AND subtype = 'QUESTION'\n",
    "                    )\n",
    "            )  \n",
    "            AND (\n",
    "                answer.PERSON_ID IN (\n",
    "                    SELECT\n",
    "                        distinct person_id  \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "                    WHERE\n",
    "                        cb_search_person.person_id IN (\n",
    "                            SELECT\n",
    "                                criteria.person_id \n",
    "                            FROM\n",
    "                                (SELECT\n",
    "                                    DISTINCT person_id,\n",
    "                                    entry_date,\n",
    "                                    concept_id \n",
    "                                FROM\n",
    "                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                                WHERE\n",
    "                                    (\n",
    "                                        concept_id IN (836812) \n",
    "                                        AND is_standard = 0  \n",
    "                                        AND  value_source_concept_id IN (43529690)\n",
    "                                    )) criteria ) \n",
    "                                AND cb_search_person.person_id IN (SELECT\n",
    "                                    person_id \n",
    "                                FROM\n",
    "                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "                                WHERE\n",
    "                                    has_whole_genome_variant = 1 ) \n",
    "                                AND cb_search_person.person_id NOT IN (SELECT\n",
    "                                    criteria.person_id \n",
    "                                FROM\n",
    "                                    (SELECT\n",
    "                                        DISTINCT person_id,\n",
    "                                        entry_date,\n",
    "                                        concept_id \n",
    "                                    FROM\n",
    "                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                                    WHERE\n",
    "                                        (\n",
    "                                            concept_id IN (\n",
    "                                                SELECT\n",
    "                                                    DISTINCT c.concept_id \n",
    "                                                FROM\n",
    "                                                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                                                JOIN\n",
    "                                                    (\n",
    "                                                        select\n",
    "                                                            cast(cr.id as string) as id \n",
    "                                                        FROM\n",
    "                                                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                                                        WHERE\n",
    "                                                            concept_id IN (381270) \n",
    "                                                            AND full_text LIKE '%_rank1]%'\n",
    "                                                    ) a \n",
    "                                                        ON (\n",
    "                                                            c.path LIKE CONCAT('%.',\n",
    "                                                        a.id,\n",
    "                                                        '.%') \n",
    "                                                        OR c.path LIKE CONCAT('%.',\n",
    "                                                        a.id) \n",
    "                                                        OR c.path LIKE CONCAT(a.id,\n",
    "                                                        '.%') \n",
    "                                                        OR c.path = a.id) \n",
    "                                                    WHERE\n",
    "                                                        is_standard = 1 \n",
    "                                                        AND is_selectable = 1\n",
    "                                                    ) \n",
    "                                                    AND is_standard = 1 \n",
    "                                            )\n",
    "                                        ) criteria \n",
    "                                    ) ))\"\"\"\n",
    "\n",
    "dataset_46445045_survey_df = pandas.read_gbq(\n",
    "    dataset_46445045_survey_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_46445045_survey_df.head(5)\n",
    "# To write the DataFrame to a CSV file:\n",
    "dataset_46445045_survey_df.to_csv(\"mar2_matproxy_survey_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include only European samples\n",
    "ancestry_pred_path = \"gs://${ALLOFUS}/v7/wgs/short_read/snpindel/aux/ancestry/ancestry_preds.tsv\"\n",
    "os.environ['ancestry_pred_path'] = ancestry_pred_path\n",
    "!gsutil -u $GOOGLE_PROJECT cat $ancestry_pred_path | cut -f1,2 | grep eur > eur_ancestry\n",
    "!grep -v person mar2_matproxy_person_df.csv | cut -f1 -d \",\" > list_of_all_mat_proxy\n",
    "!for i in `cat list_of_all_mat_proxy`; do grep $i eur_ancestry | cut -f1 >> eur_mat_cases ; done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902\r\n"
     ]
    }
   ],
   "source": [
    "#Exclude flagged and related samples\n",
    "!grep -v -F -f flagged_samples eur_mat_cases > eur_mat_unre_cases\n",
    "!grep -v -F -f flagged_samples eur_mat_cases | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRAM streaming for chrM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Package Import\n",
    "import sys\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this Python variable as an environment variable so that its easier to use within %%bash cells.\n",
    "%env JOB_ID={LINE_COUNT_JOB_ID}\n",
    "## Defining necessary pathways\n",
    "my_bucket = os.environ['WORKSPACE_BUCKET']\n",
    "my_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -1 manifest.csv > manifest_maternal.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!for i in `cat eur_mat_unre_cases` ; do grep $i manifest.csv >> manifest_maternal.csv ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l manifest_maternal.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir CRAM_Streaming_mat\n",
    "!cp manifest_maternal.csv CRAM_Streaming_mat/.\n",
    "cram_manifest = pd.read_csv('CRAM_Streaming_mat/manifest_maternal.csv')\n",
    "cram_manifest['cram_uri'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NAME = os.getenv('OWNER_EMAIL').split('@')[0].replace('.','-')\n",
    "\n",
    "# Save this Python variable as an environment variable so that its easier to use within %%bash cells.\n",
    "%env USER_NAME={USER_NAME}\n",
    "## MODIFY FOR FULL DATA RUN\n",
    "# Use hyphens, not whitespace since it will become part of the bucket path.\n",
    "JOB_NAME='CRAM_Stream_Test_mat'\n",
    "\n",
    "# Save this Python variable as an environment variable so that its easier to use within %%bash cells.\n",
    "%env JOB_NAME={JOB_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis Results Folder\n",
    "line_count_results_folder = os.path.join(\n",
    "    os.getenv('WORKSPACE_BUCKET'),\n",
    "    'dsub',\n",
    "    'results',\n",
    "    JOB_NAME,\n",
    "    USER_NAME,\n",
    "    datetime.now().strftime('%Y%m%d'))\n",
    "\n",
    "line_count_results_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Where the output files will go\n",
    "output_files = os.path.join(line_count_results_folder, \"results\")\n",
    "print(output_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILES = output_files\n",
    "\n",
    "\n",
    "# Save this Python variable as an environment variable so that its easier to use within %%bash cells.\n",
    "%env OUTPUT_FILES={OUTPUT_FILES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.04"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cram_count = len(cram_manifest)\n",
    "cram_count\n",
    "jobs = cram_count/50\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating batches of 10 will be larger for samples\n",
    "##Crams 2-101\n",
    "##For full just making a df with all crams\n",
    "test_crams = cram_manifest['cram_uri'].iloc[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/workspaces/neurologicalgenescreening/CRAM_Streaming_mat\r\n"
     ]
    }
   ],
   "source": [
    "## Made a batch folder\n",
    "!mkdir CRAM_Streaming_mat/batches\n",
    "!realpath CRAM_Streaming_mat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting into ten files with ten cram pathways per \n",
    "## Copy batch realpath output above into '' in the to_csv command being sure to keep the single quotes\n",
    "## At the end of the path, be sure to add /cram_batch_{id}.txt \n",
    "for id, test_crams_i in  enumerate(np.array_split(test_crams, 30)):\n",
    "    test_crams_i.to_csv('/home/jupyter/workspaces/neurologicalgenescreening/CRAM_Streaming_mat/batches/cram_batch_{id}.txt'.format(id=id), index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Coping batches to user directory\n",
    "!gsutil -m cp CRAM_Streaming_mat/batches/* {my_bucket}/dsub/final_batches/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30 CRAM_Streaming_mat/batches/cram_batch_8.txt\n"
     ]
    }
   ],
   "source": [
    "!ls CRAM_Streaming_mat/batches/ | wc -l\n",
    "!wc -l CRAM_Streaming_mat/batches/cram_batch_8.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Generated batch file\n",
    "!gsutil ls {my_bucket}/dsub/final_batches/*.txt > AoU_batches_mat.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Move batch file\n",
    "## Use realpath output above again in this command:\n",
    "!mv AoU_batches_mat.txt /home/jupyter/workspaces/neurologicalgenescreening/CRAM_Streaming_mat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/workspaces/neurologicalgenescreening/CRAM_Streaming_mat/AoU_batches_mat.txt\r\n"
     ]
    }
   ],
   "source": [
    "!realpath CRAM_Streaming_mat/AoU_batches_mat.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/jupyter/printreads_depth_CRAM_Stream.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/printreads_depth_CRAM_Stream.sh\n",
    "\n",
    "set -o pipefail\n",
    "set -o errexit\n",
    "\n",
    "# ---------Required Inputs---------\n",
    "# aou_crams - A .txt file containing gs:// paths to cram samples.\n",
    "\n",
    "# Given a .txt file - get X samples.\n",
    "# For parallel submissions:\n",
    "# - Use a different .txt file per submission.\n",
    "# - Each .txt file can contain a different number of lines\n",
    "aou_crams_len=$(wc -l < ${aou_crams})\n",
    "echo \"Samples in cramlist: ${aou_crams_len}\"\n",
    "\n",
    "# ---------Required Output---------\n",
    "#filtered_cram_output\n",
    "\n",
    "echo \"GOOGLE_PROJECT: ${GOOGLE_PROJECT}\"\n",
    "echo \"OUTPUT_PATH: ${OUTPUT_PATH}\"\n",
    "echo \"ref_dict: ${ref_dict}\"\n",
    "echo \"ref_fai: ${ref_fai}\"\n",
    "echo \"ref_fasta: ${ref_fasta}\"\n",
    "\n",
    "# Perform runs for x samples.\n",
    "for (( i=1; i<$aou_crams_len+1; i++ ));\n",
    "do\n",
    "\n",
    "    # These change per iteration\n",
    "    export aou_cram_reads=$(sed \"${i}!d;q\" \"${aou_crams}\")   # gs:// path to a cram sample\n",
    "    export aou_cram_reads_name=`basename ${aou_cram_reads}`  # file_name.cram\n",
    "    export aou_cram_reads_prefix=\"${aou_cram_reads_name%.*}\" # file_name\n",
    "    echo \"aou_cram_reads: ${aou_cram_reads}\"\n",
    "    echo \"aou_cram_reads_name: ${aou_cram_reads_name}\"\n",
    "    echo \"aou_cram_reads_prefix: ${aou_cram_reads_prefix}\"\n",
    "\n",
    "    # ----------------------------------WORKFLOW----------------------------------\n",
    "\n",
    "    # Stream CRAM found at gs:// path into a new, smaller CRAM based on genomic intervals given with -L.\n",
    "    /gatk/gatk PrintReads \\\n",
    "        -I ${aou_cram_reads} \\\n",
    "        -L \"chrM\" \\\n",
    "        -R \"${ref_fasta}\" \\\n",
    "        -O \"${aou_cram_reads_prefix}_mt_control.cram\" \\\n",
    "        --gcs-project-for-requester-pays ${GOOGLE_PROJECT} \\\n",
    "        --cloud-prefetch-buffer 0 --cloud-index-prefetch-buffer 0\n",
    "\n",
    "    # Outputs\n",
    "    export igk_depth_cram=\"${aou_cram_reads_prefix}_mt_control.cram\"\n",
    "    echo \"igk_depth_cram: ${igk_depth_cram}\"\n",
    "\n",
    "    # Disk space\n",
    "    echo \"Disk space taken up so far:\"\n",
    "    du -d 1 -h\n",
    "    echo \"${i} run(s) finished.\"\n",
    "\n",
    "    # Move results to output directory\n",
    "    mv ${igk_depth_cram} ${OUTPUT_PATH}\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///home/jupyter/printreads_depth_CRAM_Stream.sh [Content-Type=text/x-sh]...\n",
      "/ [1 files][  1.9 KiB/  1.9 KiB]                                                \n",
      "Operation completed over 1 objects/1.9 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp /home/jupyter/printreads_depth_CRAM_Stream.sh {my_bucket}/dsub/scripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy this cell's output to the BASH_SCRIPT variable in cell 33, the dsub command below\n",
    "!gsutil ls {my_bucket}/dsub/scripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp CRAM_Streaming_mat/AoU_batches_mat.txt ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --out LINE_COUNT_JOB_ID\n",
    "\n",
    "# Get a shorter username to leave more characters for the job name.\n",
    "DSUB_USER_NAME=\"$(echo \"${OWNER_EMAIL}\" | cut -d@ -f1)\"\n",
    "\n",
    "# For AoU RWB projects network name is \"network\".\n",
    "AOU_NETWORK=network\n",
    "AOU_SUBNETWORK=subnetwork\n",
    "\n",
    "# Get all cramlists\n",
    "bashArray=()\n",
    "\n",
    "## ------------------------------------------------ MAKE CHANGES HERE ------------------------------------------\n",
    "#Change the 'done < test_cram_batch.txt' to 'done < AoU_v7_batches.txt' if you want to run across all batches\n",
    "while read line; do\n",
    "  bashArray+=($line)\n",
    "done < AoU_batches_mat.txt\n",
    "## -------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Length of entire array\n",
    "len_bashArray=${#bashArray[@]}\n",
    "\n",
    "LOWER=0\n",
    "UPPER=$len_bashArray\n",
    "MACHINE_TYPE=\"n2-standard-4\"\n",
    "## ------------------------------------------------ MAKE CHANGES HERE ------------------------------------------\n",
    "DATE=20230301\n",
    "BASH_SCRIPT=\"${WORKSPACE_BUCKET}/dsub/scripts/printreads_depth_CRAM_Stream.sh\"\n",
    "## -------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "for ((batch=$LOWER;batch<$UPPER;batch+=1))\n",
    "do\n",
    "    dsub \\\n",
    "        --provider google-cls-v2 \\\n",
    "        --user-project \"${GOOGLE_PROJECT}\"\\\n",
    "        --project \"${GOOGLE_PROJECT}\"\\\n",
    "        --network \"${AOU_NETWORK}\" \\\n",
    "        --subnetwork \"${AOU_SUBNETWORK}\" \\\n",
    "        --service-account \"$(gcloud config get-value account)\" \\\n",
    "        --user \"${DSUB_USER_NAME}\" \\\n",
    "        --regions us-central1 \\\n",
    "        --logging \"${WORKSPACE_BUCKET}/dsub/logs/{job-name}/{user-id}/${DATE}/${bashArray[batch]}.log\" \\\n",
    "        \"$@\" \\\n",
    "        --preemptible \\\n",
    "        --boot-disk-size 100 \\\n",
    "        --machine-type ${MACHINE_TYPE} \\\n",
    "        --disk-size 100 \\\n",
    "        --name \"${JOB_NAME}\" \\\n",
    "        --script \"${BASH_SCRIPT}\" \\\n",
    "        --image 'gcr.io/bick-aps2/briansha/pileup_preprocessing:latest' \\\n",
    "        --env GOOGLE_PROJECT=${GOOGLE_PROJECT} \\\n",
    "        --input ref_dict=\"${WORKSPACE_BUCKET}/data/Homo_sapiens_assembly38.dict\" \\\n",
    "        --input ref_fai=\"${WORKSPACE_BUCKET}/data/Homo_sapiens_assembly38.fasta.fai\" \\\n",
    "        --input ref_fasta=\"${WORKSPACE_BUCKET}/data/Homo_sapiens_assembly38.fasta\" \\\n",
    "        --input aou_crams=\"${bashArray[batch]}\" \\\n",
    "        --output-recursive OUTPUT_PATH=\"${OUTPUT_FILES}/${batch}\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Name         Status    Last Update\r\n",
      "---------------  --------  --------------\r\n",
      "cram-stream-...  Success   03-08 22:08:47\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!dstat --provider google-cls-v2 --project ${GOOGLE_PROJECT} --location us-central1 --jobs 'cram-strea--fulyaakcimen--240308-220245-41' --users 'fulyaakcimen' --status '*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!for i in 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  ; do  gsutil -o 'GSUtil:parallel_thread_count=20' -m cp -r ${WORKSPACE_BUCKET}/dsub/results/CRAM_Stream_Test_mat/fulyaakcimen/20240308/results/$i/wgs_*_mt_control.cram mat_prox/. ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index cram files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!for i in `cat proxy_crams` ; do samtools index $i ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -100 proxy_crams > proxy_crams_1\n",
    "!head -200 proxy_crams | tail -100 > proxy_crams_2\n",
    "!head -300 proxy_crams | tail -100 > proxy_crams_3\n",
    "!head -400 proxy_crams | tail -100 > proxy_crams_4\n",
    "!head -500 proxy_crams | tail -100 > proxy_crams_5\n",
    "!head -600 proxy_crams | tail -100 > proxy_crams_6\n",
    "!head -700 proxy_crams | tail -100 > proxy_crams_7\n",
    "!head -800 proxy_crams | tail -100 > proxy_crams_8\n",
    "!head -902 proxy_crams | tail -102 > proxy_crams_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the for loop for 9 proxy_crams batches\n",
    "!for i in `cat proxy_crams_1` ; do gatk --java-options \"-Xmx10G\" Mutect2 -R Homo_sapiens_assembly38.fasta -L chrM --mitochondria-mode -I $i -O \"$i\".vcf.gz ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bcftools merge mat_prox/*gz -Oz -o merged_mat.vcf.gz --force-samples -r chrM:2157-2159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!plink2 --vcf merged_mat.vcf.gz --make-bed --double-id --out merged_mat_eur \\\n",
    "--chr MT --from-bp 2158 --to-bp 2158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!plink --bfile merged_mat_eur --fill-missing-a2 --make-bed --out merged_mat_eur_misupd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!plink2 --bfile merged_mat_eur_misupd --freq --out mat_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!plink --bfile  merged_mat_eur_misupd --bmerge PDfiltecontrols --make-bed --out PD_matcontrols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!plink2 --bfile PD_matcontrols --glm firth-fallback --pheno mat_pheno --pheno-name PHENO --ci 0.95 --vif 100 \\\n",
    "--out mat_proxytest --covar mat_pheno --covar-name age,SEX,PC1,PC2,PC3,PC4,PC5,PC6,PC7,PC8,PC9,PC10  --covar-variance-standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#CHROM\tPOS\tID\tREF\tALT\tA1\tFIRTH?\tTEST\tOBS_CT\tOR\tLOG(OR)_SE\tL95\tU95\tZ_STAT\tP\r\n",
      "MT\t2158\t.\tT\tC\tC\tN\tADD\t13544\t0.685152\t0.806072\t0.141142\t3.32596\t-0.469082\t0.639011\r\n",
      "MT\t2158\t.\tT\tC\tC\tN\tPC1\t13544\t0.972167\t0.0560921\t0.870954\t1.08514\t-0.503242\t0.614794\r\n",
      "MT\t2158\t.\tT\tC\tC\tN\tPC2\t13544\t1.15029\t0.0740261\t0.994935\t1.32989\t1.89137\t0.0585745\r\n",
      "MT\t2158\t.\tT\tC\tC\tN\tPC3\t13544\t0.906594\t0.0701327\t0.790162\t1.04018\t-1.39821\t0.16205\r\n",
      "MT\t2158\t.\tT\tC\tC\tN\tPC4\t13544\t0.878755\t0.100063\t0.722262\t1.06916\t-1.29168\t0.196469\r\n",
      "MT\t2158\t.\tT\tC\tC\tN\tPC5\t13544\t0.970547\t0.0735408\t0.840269\t1.12102\t-0.406521\t0.68436\r\n",
      "MT\t2158\t.\tT\tC\tC\tN\tPC6\t13544\t1.15911\t0.467093\t0.464016\t2.89544\t0.316103\t0.751924\r\n",
      "MT\t2158\t.\tT\tC\tC\tN\tPC7\t13544\t0.870048\t0.490016\t0.332997\t2.27324\t-0.284087\t0.776344\r\n",
      "MT\t2158\t.\tT\tC\tC\tN\tPC8\t13544\t0.92398\t0.168233\t0.664451\t1.28488\t-0.469973\t0.638374\r\n",
      "MT\t2158\t.\tT\tC\tC\tN\tPC9\t13544\t0.928382\t0.0644666\t0.818187\t1.05342\t-1.15272\t0.249026\r\n",
      "MT\t2158\t.\tT\tC\tC\tN\tPC10\t13544\t1.04365\t0.0417646\t0.961627\t1.13268\t1.02307\t0.306274\r\n",
      "MT\t2158\t.\tT\tC\tC\tN\tSEX=Female\t13544\t0.909866\t0.0858416\t0.768969\t1.07658\t-1.10038\t0.271168\r\n",
      "MT\t2158\t.\tT\tC\tC\tN\tage\t13544\t0.229834\t0.0534897\t0.206959\t0.255238\t-27.4894\t2.35373e-166\r\n"
     ]
    }
   ],
   "source": [
    "!cat mat_proxytest.PHENO.glm.logistic.hybrid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
